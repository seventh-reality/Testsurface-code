<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebAR with Green Screen Video</title>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            font-family: Arial, sans-serif;
        }
        model-viewer {
            width: 100%;
            height: 100vh;
            background-color: #000;
        }
        .controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0,0,0,0.7);
            padding: 10px 20px;
            border-radius: 20px;
            color: white;
            text-align: center;
        }
        select {
            padding: 8px 15px;
            border-radius: 10px;
            margin-top: 5px;
            background: #333;
            color: white;
            border: none;
        }
    </style>
</head>
<body>
    <model-viewer 
        id="ar-model"
        camera-controls 
        touch-action="pan-y" 
        src="https://modelviewer.dev/shared-assets/models/sphere.glb" 
        ar 
        ar-modes="webxr scene-viewer quick-look" 
        alt="AR with Green Screen Video"
        xr-environment
    >
        <div class="controls">
            <p>Video Source</p>
            <select id="video-source">
                <option value="greenscreen">Green Screen Video</option>
                <option value="regular">Regular Video</option>
            </select>
        </div>
    </model-viewer>

    <script type="module">
        const modelViewer = document.querySelector("#ar-model");
        let videoTexture = null;
        let processedVideoTexture = null;
        let videoElement = null;

        // Green screen processing shader
        const greenscreenShader = `
            precision highp float;
            uniform sampler2D uTexture;
            varying vec2 vUv;
            
            void main() {
                vec4 color = texture2D(uTexture, vUv);
                
                // Green screen removal (adjust these values as needed)
                float greenAmount = color.g;
                float blueAmount = color.b;
                float redAmount = color.r;
                
                // Chroma key algorithm (adjust threshold as needed)
                if (greenAmount > 0.8 && blueAmount < 0.4 && redAmount < 0.4) {
                    discard;
                }
                
                gl_FragColor = color;
            }
        `;

        // Create processed video texture with green screen removal
        async function createProcessedVideoTexture(videoUrl) {
            if (!videoElement) {
                videoElement = document.createElement('video');
                videoElement.src = videoUrl;
                videoElement.crossOrigin = "anonymous";
                videoElement.loop = true;
                videoElement.muted = true;
                videoElement.playsInline = true;
                await videoElement.play();
            }

            const canvas = document.createElement('canvas');
            canvas.width = 1280;
            canvas.height = 720;
            const ctx = canvas.getContext('2d');

            // Create off-screen WebGL context for processing
            const offscreenCanvas = document.createElement('canvas');
            offscreenCanvas.width = canvas.width;
            offscreenCanvas.height = canvas.height;
            const gl = offscreenCanvas.getContext('webgl');

            if (!gl) {
                console.error("WebGL not supported for green screen processing");
                return modelViewer.createVideoTexture(videoUrl);
            }

            // Setup WebGL program
            const vertexShader = gl.createShader(gl.VERTEX_SHADER);
            gl.shaderSource(vertexShader, `
                attribute vec2 aPosition;
                varying vec2 vUv;
                void main() {
                    vUv = aPosition * 0.5 + 0.5;
                    gl_Position = vec4(aPosition, 0.0, 1.0);
                }
            `);
            gl.compileShader(vertexShader);

            const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
            gl.shaderSource(fragmentShader, greenscreenShader);
            gl.compileShader(fragmentShader);

            const program = gl.createProgram();
            gl.attachShader(program, vertexShader);
            gl.attachShader(program, fragmentShader);
            gl.linkProgram(program);
            gl.useProgram(program);

            // Setup geometry
            const positionBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
                -1, -1, 1, -1, -1, 1,
                -1, 1, 1, -1, 1, 1
            ]), gl.STATIC_DRAW);

            const positionLocation = gl.getAttribLocation(program, "aPosition");
            gl.enableVertexAttribArray(positionLocation);
            gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

            // Create texture
            const texture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);

            // Animation loop
            function processFrame() {
                if (videoElement.readyState >= videoElement.HAVE_ENOUGH_DATA) {
                    // Draw video to canvas
                    ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
                    
                    // Update WebGL texture
                    gl.bindTexture(gl.TEXTURE_2D, texture);
                    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, canvas);
                    
                    // Render processed frame
                    gl.viewport(0, 0, offscreenCanvas.width, offscreenCanvas.height);
                    gl.clear(gl.COLOR_BUFFER_BIT);
                    gl.drawArrays(gl.TRIANGLES, 0, 6);
                    
                    // Read pixels back to canvas
                    gl.readPixels(0, 0, offscreenCanvas.width, offscreenCanvas.height, gl.RGBA, gl.UNSIGNED_BYTE, new Uint8Array(ctx.getImageData(0, 0, canvas.width, canvas.height).data.buffer));
                }
                requestAnimationFrame(processFrame);
            }
            processFrame();

            return canvas;
        }

        // Initialize AR experience
        customElements.whenDefined('model-viewer').then(async () => {
            // Create regular video texture
            videoTexture = modelViewer.createVideoTexture("https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_1mb.mp4");
            
            // Create green screen video texture (replace with your green screen video)
            const greenscreenVideoUrl = "https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_1mb.mp4";
            processedVideoTexture = await createProcessedVideoTexture(greenscreenVideoUrl);

            modelViewer.addEventListener("load", () => {
                const material = modelViewer.model.materials[0];
                const { baseColorTexture } = material.pbrMetallicRoughness;
                
                // Set initial texture
                baseColorTexture.setTexture(processedVideoTexture);

                // Handle video source change
                document.querySelector('#video-source').addEventListener('change', (event) => {
                    if (event.target.value === "greenscreen") {
                        baseColorTexture.setTexture(processedVideoTexture);
                    } else {
                        baseColorTexture.setTexture(videoTexture);
                    }
                });
            });
        });

        // Add AR button for iOS
        document.addEventListener('DOMContentLoaded', () => {
            if (/iPad|iPhone|iPod/.test(navigator.userAgent)) {
                const button = document.createElement('button');
                button.textContent = 'View in AR';
                button.style.position = 'fixed';
                button.style.bottom = '80px';
                button.style.left = '50%';
                button.style.transform = 'translateX(-50%)';
                button.style.padding = '10px 20px';
                button.style.background = '#4285f4';
                button.style.color = 'white';
                button.style.border = 'none';
                button.style.borderRadius = '20px';
                button.style.zIndex = '10';
                button.addEventListener('click', () => {
                    modelViewer.activateAR();
                });
                document.body.appendChild(button);
            }
        });
    </script>
</body>
</html>
