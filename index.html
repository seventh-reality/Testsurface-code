<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>AlvaAR SLAM Surface Tracking with GLB Model</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            overflow: hidden;
            font-family: Arial, sans-serif;
        }
        #ar-container {
            position: absolute;
            width: 100%;
            height: 100%;
        }
        #loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
        }
        #instructions {
            position: absolute;
            bottom: 20px;
            left: 0;
            right: 0;
            text-align: center;
            color: white;
            background: rgba(0, 0, 0, 0.5);
            padding: 10px;
            margin: 0 auto;
            width: 80%;
            border-radius: 5px;
        }
    </style>
    <!-- Include AlvaAR WebAR library -->
    <script src="https://cdn.alva-ar.com/latest/alvaar.js"></script>
    <!-- Include Three.js for GLB model rendering -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- GLTFLoader for loading GLB models -->
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.min.js"></script>
</head>
<body>
    <div id="ar-container"></div>
    <div id="loading">Initializing AR experience...</div>
    <div id="instructions" style="display: none;">Move your device to detect surfaces. Tap to place the object.</div>

    <script>
        // Configuration
        const config = {
            containerId: 'ar-container',
            modelUrl: 'all.glb', // Replace with your GLB model URL
            modelScale: 0.5, // Adjust scale as needed
            modelPlacementHeight: 0 // Height above the detected surface
        };

        // Variables
        let alvaAR = null;
        let threeScene = null;
        let threeCamera = null;
        let threeRenderer = null;
        let model = null;
        let placed = false;
        let tapPosition = new THREE.Vector2();

        // Initialize the AR experience
        async function init() {
            try {
                // Initialize AlvaAR
                alvaAR = new AlvaAR.AlvaAR({
                    container: document.getElementById(config.containerId),
                    trackingMode: AlvaAR.TrackingMode.SLAM,
                    surfaceTracking: true
                });

                // Wait for initialization
                await alvaAR.init();

                // Initialize Three.js scene
                initThreeJS();

                // Load the GLB model
                await loadModel();

                // Hide loading message and show instructions
                document.getElementById('loading').style.display = 'none';
                document.getElementById('instructions').style.display = 'block';

                // Start the AR experience
                startAR();

            } catch (error) {
                console.error('Initialization error:', error);
                document.getElementById('loading').textContent = 'Error initializing AR. Please try again.';
            }
        }

        // Initialize Three.js scene
        function initThreeJS() {
            // Create Three.js scene
            threeScene = new THREE.Scene();
            
            // Create Three.js camera (will be updated each frame to match AR camera)
            threeCamera = new THREE.PerspectiveCamera();
            threeScene.add(threeCamera);
            
            // Create Three.js renderer
            threeRenderer = new THREE.WebGLRenderer({
                alpha: true,
                antialias: true
            });
            threeRenderer.setPixelRatio(window.devicePixelRatio);
            threeRenderer.setSize(window.innerWidth, window.innerHeight);
            threeRenderer.autoClear = false;
            
            // Add renderer to DOM
            document.getElementById(config.containerId).appendChild(threeRenderer.domElement);
            
            // Add lights to the scene
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
            threeScene.add(ambientLight);
            
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(1, 1, 1);
            threeScene.add(directionalLight);
        }

        // Load the GLB model
        async function loadModel() {
            return new Promise((resolve, reject) => {
                const loader = new THREE.GLTFLoader();
                
                loader.load(
                    config.modelUrl,
                    (gltf) => {
                        model = gltf.scene;
                        model.scale.set(config.modelScale, config.modelScale, config.modelScale);
                        model.visible = false; // Hide until placed
                        threeScene.add(model);
                        resolve();
                    },
                    undefined,
                    (error) => {
                        console.error('Error loading model:', error);
                        reject(error);
                    }
                );
            });
        }

        // Start the AR experience
        function startAR() {
            // Handle window resize
            window.addEventListener('resize', onWindowResize);
            
            // Handle touch events for model placement
            window.addEventListener('touchstart', onTouchStart, false);
            window.addEventListener('click', onClick, false);
            
            // Start the AR render loop
            alvaAR.run(renderLoop);
        }

        // AR render loop
        function renderLoop(poseMatrix, projectionMatrix) {
            if (!poseMatrix || !projectionMatrix) return;
            
            // Update Three.js camera with AR camera pose
            threeCamera.matrix.fromArray(poseMatrix);
            threeCamera.matrix.decompose(threeCamera.position, threeCamera.quaternion, threeCamera.scale);
            threeCamera.projectionMatrix.fromArray(projectionMatrix);
            threeCamera.updateMatrixWorld(true);
            
            // If model is placed, keep it at its position
            if (placed && model) {
                // You could add animation or interaction logic here
            }
            
            // Render Three.js scene
            threeRenderer.clear();
            threeRenderer.render(threeScene, threeCamera);
            
            // Request next frame
            requestAnimationFrame(() => alvaAR.run(renderLoop));
        }

        // Handle touch/click for model placement
        function onTouchStart(event) {
            if (placed) return;
            
            // Get touch position
            tapPosition.x = (event.touches[0].clientX / window.innerWidth) * 2 - 1;
            tapPosition.y = -(event.touches[0].clientY / window.innerHeight) * 2 + 1;
            
            placeModel();
        }

        function onClick(event) {
            if (placed) return;
            
            // Get click position
            tapPosition.x = (event.clientX / window.innerWidth) * 2 - 1;
            tapPosition.y = -(event.clientY / window.innerHeight) * 2 + 1;
            
            placeModel();
        }

        // Place the model on a detected surface
        function placeModel() {
            if (!model || placed) return;
            
            // Raycast to find surface
            const raycaster = new THREE.Raycaster();
            raycaster.setFromCamera(tapPosition, threeCamera);
            
            // In a real implementation, you would use AlvaAR's surface detection
            // For this example, we'll place the model in front of the camera
            const distance = 1.0; // Distance from camera
            const direction = new THREE.Vector3(0, 0, -1).applyQuaternion(threeCamera.quaternion);
            
            model.position.copy(threeCamera.position).add(direction.multiplyScalar(distance));
            model.position.y += config.modelPlacementHeight; // Adjust height
            
            // Make model face the camera
            model.quaternion.copy(threeCamera.quaternion);
            
            model.visible = true;
            placed = true;
            
            document.getElementById('instructions').textContent = 'Model placed! Move around to view it.';
        }

        // Handle window resize
        function onWindowResize() {
            threeRenderer.setSize(window.innerWidth, window.innerHeight);
        }

        // Start the application
        window.addEventListener('load', init);
    </script>
</body>
</html>
