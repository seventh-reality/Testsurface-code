<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebAR with Green Screen Video</title>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            font-family: Arial, sans-serif;
        }
        model-viewer {
            width: 100%;
            height: 100vh;
            background-color: #000;
        }
        .controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0,0,0,0.7);
            padding: 10px 20px;
            border-radius: 20px;
            color: white;
            text-align: center;
        }
        select {
            padding: 8px 15px;
            border-radius: 10px;
            margin-top: 5px;
            background: #333;
            color: white;
            border: none;
        }
        #loading {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.8);
            color: white;
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 100;
        }
    </style>
</head>
<body>
    <div id="loading">Loading AR experience...</div>
    <model-viewer 
        id="ar-model"
        camera-controls 
        touch-action="pan-y" 
        src="https://modelviewer.dev/shared-assets/models/sphere.glb" 
        ar 
        ar-modes="webxr scene-viewer quick-look" 
        alt="AR with Green Screen Video"
        xr-environment
    >
        <div class="controls">
            <p>Video Source</p>
            <select id="video-source">
                <option value="greenscreen">Green Screen Video</option>
                <option value="regular">Regular Video</option>
            </select>
        </div>
    </model-viewer>

    <script type="module">
        const modelViewer = document.querySelector("#ar-model");
        const loadingElement = document.querySelector("#loading");
        let videoTexture = null;
        let processedVideoTexture = null;
        let videoElement = null;
        let processingCanvas = null;

        // Green screen processing shader
        const greenscreenShader = `
            precision highp float;
            uniform sampler2D uTexture;
            varying vec2 vUv;
            
            void main() {
                vec4 color = texture2D(uTexture, vUv);
                
                // Green screen removal (adjust these values as needed)
                float greenAmount = color.g;
                float blueAmount = color.b;
                float redAmount = color.r;
                
                // Chroma key algorithm (adjust threshold as needed)
                if (greenAmount > max(blueAmount, redAmount) * 1.5 && greenAmount > 0.4) {
                    discard;
                }
                
                gl_FragColor = color;
            }
        `;

        // Helper function to wait for video to be ready
        function waitForVideoReady(video) {
            return new Promise((resolve) => {
                const checkReady = () => {
                    if (video.readyState >= 2) { // HAVE_CURRENT_DATA
                        resolve();
                    } else {
                        setTimeout(checkReady, 100);
                    }
                };
                checkReady();
            });
        }

        // Create processed video texture with green screen removal
        async function createProcessedVideoTexture(videoUrl) {
            try {
                videoElement = document.createElement('video');
                videoElement.src = videoUrl;
                videoElement.crossOrigin = "anonymous";
                videoElement.loop = true;
                videoElement.muted = true;
                videoElement.playsInline = true;
                
                // iOS requires user interaction to play video
                if (/iPad|iPhone|iPod/.test(navigator.userAgent)) {
                    // Create a transparent overlay to capture user interaction
                    const overlay = document.createElement('div');
                    overlay.style.position = 'fixed';
                    overlay.style.top = '0';
                    overlay.style.left = '0';
                    overlay.style.width = '100%';
                    overlay.style.height = '100%';
                    overlay.style.zIndex = '1000';
                    overlay.style.background = 'transparent';
                    document.body.appendChild(overlay);
                    
                    return new Promise((resolve) => {
                        overlay.addEventListener('click', async () => {
                            document.body.removeChild(overlay);
                            await videoElement.play();
                            resolve(await processVideoFrames());
                        }, { once: true });
                    });
                } else {
                    await videoElement.play();
                    return processVideoFrames();
                }
            } catch (error) {
                console.error("Video playback error:", error);
                loadingElement.textContent = "Error loading video. Please interact with the page.";
                throw error;
            }
        }

        async function processVideoFrames() {
            processingCanvas = document.createElement('canvas');
            processingCanvas.width = 1280;
            processingCanvas.height = 720;
            const ctx = processingCanvas.getContext('2d');

            // Create off-screen WebGL context for processing
            const offscreenCanvas = document.createElement('canvas');
            offscreenCanvas.width = processingCanvas.width;
            offscreenCanvas.height = processingCanvas.height;
            const gl = offscreenCanvas.getContext('webgl');

            if (!gl) {
                console.error("WebGL not supported for green screen processing");
                return modelViewer.createVideoTexture(videoElement.src);
            }

            // Setup WebGL program
            const vertexShader = gl.createShader(gl.VERTEX_SHADER);
            gl.shaderSource(vertexShader, `
                attribute vec2 aPosition;
                varying vec2 vUv;
                void main() {
                    vUv = aPosition * 0.5 + 0.5;
                    gl_Position = vec4(aPosition, 0.0, 1.0);
                }
            `);
            gl.compileShader(vertexShader);

            const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
            gl.shaderSource(fragmentShader, greenscreenShader);
            gl.compileShader(fragmentShader);

            const program = gl.createProgram();
            gl.attachShader(program, vertexShader);
            gl.attachShader(program, fragmentShader);
            gl.linkProgram(program);
            gl.useProgram(program);

            // Setup geometry
            const positionBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
                -1, -1, 1, -1, -1, 1,
                -1, 1, 1, -1, 1, 1
            ]), gl.STATIC_DRAW);

            const positionLocation = gl.getAttribLocation(program, "aPosition");
            gl.enableVertexAttribArray(positionLocation);
            gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

            // Create texture
            const texture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);

            // Wait for video to have enough data
            await waitForVideoReady(videoElement);

            // Create initial texture
            ctx.drawImage(videoElement, 0, 0, processingCanvas.width, processingCanvas.height);
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, processingCanvas);

            // Return a texture that will be updated in the animation loop
            return processingCanvas;
        }

        // Initialize AR experience
        customElements.whenDefined('model-viewer').then(async () => {
            try {
                // Create regular video texture
                videoTexture = modelViewer.createVideoTexture("https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4");
                
                // Create green screen video texture
                const greenscreenVideoUrl = "Tiger.mp4"; // Replace with your video path
                processedVideoTexture = await createProcessedVideoTexture(greenscreenVideoUrl);

                modelViewer.addEventListener("load", () => {
                    loadingElement.style.display = 'none';
                    const material = modelViewer.model.materials[0];
                    const { baseColorTexture } = material.pbrMetallicRoughness;
                    
                    // Set initial texture
                    baseColorTexture.setTexture(processedVideoTexture);

                    // Handle video source change
                    document.querySelector('#video-source').addEventListener('change', (event) => {
                        if (event.target.value === "greenscreen") {
                            baseColorTexture.setTexture(processedVideoTexture);
                        } else {
                            baseColorTexture.setTexture(videoTexture);
                        }
                    });

                    // Animation loop to update processed video
                    function updateVideoTexture() {
                        if (videoElement && processingCanvas && videoElement.readyState >= videoElement.HAVE_CURRENT_DATA) {
                            const ctx = processingCanvas.getContext('2d');
                            ctx.drawImage(videoElement, 0, 0, processingCanvas.width, processingCanvas.height);
                        }
                        requestAnimationFrame(updateVideoTexture);
                    }
                    updateVideoTexture();
                });
            } catch (error) {
                console.error("AR initialization error:", error);
                loadingElement.textContent = "Error initializing AR. Please refresh the page.";
            }
        });

        // Add AR button for iOS
        document.addEventListener('DOMContentLoaded', () => {
            if (/iPad|iPhone|iPod/.test(navigator.userAgent)) {
                const button = document.createElement('button');
                button.textContent = 'View in AR';
                button.style.position = 'fixed';
                button.style.bottom = '80px';
                button.style.left = '50%';
                button.style.transform = 'translateX(-50%)';
                button.style.padding = '10px 20px';
                button.style.background = '#4285f4';
                button.style.color = 'white';
                button.style.border = 'none';
                button.style.borderRadius = '20px';
                button.style.zIndex = '10';
                button.addEventListener('click', () => {
                    modelViewer.activateAR();
                });
                document.body.appendChild(button);
            }
        });
    </script>
</body>
</html>
